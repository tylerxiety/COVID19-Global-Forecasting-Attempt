{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# greet the data\\nprint(df.describe())\\nprint(\"-\"*65)\\nprint(df.describe(include=[\\'O\\']))\\nprint(\"-\"*65)\\nprint(df.info())'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# greet the data\n",
    "print(df.describe())\n",
    "print(\"-\"*65)\n",
    "print(df.describe(include=['O']))\n",
    "print(\"-\"*65)\n",
    "print(df.info())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing datasets and actual labels\n",
    "train = df.copy()\n",
    "train = train[train.Date <= '2020-05-10']\n",
    "\n",
    "test = df.copy()\n",
    "test = test[(test['Date']>='2020-05-11')&(test['Date']<='2020-05-17')]\n",
    "\n",
    "actuals = test.TargetValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# seems like the data is cleaned\\ntrain.Country_Region.unique().tolist()\\ntrain.County.unique().tolist()\\ntrain.Province_State.unique().tolist()'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# seems like the data is cleaned\n",
    "train.Country_Region.unique().tolist()\n",
    "train.County.unique().tolist()\n",
    "train.Province_State.unique().tolist()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# See the training data\\nprint(train.describe())\\nprint(\"-\"*65)\\nprint(train.describe(include=[\\'O\\']))\\nprint(\"-\"*65)\\nprint(train.info())'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# See the training data\n",
    "print(train.describe())\n",
    "print(\"-\"*65)\n",
    "print(train.describe(include=['O']))\n",
    "print(\"-\"*65)\n",
    "print(train.info())'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of ideas for models:\n",
    "- quntile linear regression from mlinsights\n",
    "- quantile gradient boosting regressor from sklearn\n",
    "- quantile regression forests from skargen\n",
    "- quantile deep net using Keras or Tensorflow\n",
    "\n",
    "A couple of ideas for the missing values:\n",
    "- drop \n",
    "- impute\n",
    "- impute with mark on which ones are missing\n",
    "\n",
    "A couple of ideas for the columns:\n",
    "\n",
    "- County: drop or keep\n",
    "- Province_State: drop or keep\n",
    "- Population: bins or as is\n",
    "- Date: day of week, day of month, month, day of year\n",
    "\n",
    "- relationship b/w confirmed and death?\n",
    "\n",
    "- New columns:Continuent ?\n",
    "\n",
    "Ways of encoding\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Weighted Pinball Loss function\n",
    "\n",
    "def PLoss(preds, actuals, qt):\n",
    "    loss = np.maximum((actuals-preds)*qt, (preds-actuals)*(1-qt))\n",
    "    return loss\n",
    "\n",
    "def WPLoss(preds05, preds50, preds95, actuals, weights):\n",
    "    l05 = PLoss(preds05, actuals,0.05)\n",
    "    l50 = PLoss(preds50, actuals,0.5)\n",
    "    l95 = PLoss(preds95, actuals,0.95)\n",
    "    score = sum((l05+l50+l95)/3*weights)/actuals.count()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label y\n",
    "y = train.TargetValue\n",
    "\n",
    "# Clean train and test data\n",
    "train = train.drop(['Id','TargetValue'],axis=1)\n",
    "testId = test.Id\n",
    "test = test.drop(['Id','TargetValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode and creat X\n",
    "train_encoded = pd.get_dummies(train)\n",
    "test_encoded = pd.get_dummies(test)\n",
    "\n",
    "train_ali, test_ali = train_encoded.align(test_encoded, join='left', axis=1)\n",
    "\n",
    "X=train_ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into validation and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the models with droping the columns with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with missing values \n",
    "cols_with_missing = [col for col in train_X.columns \n",
    "                                 if train_X[col].isnull().any()]\n",
    "\n",
    "train_X_noMis = train_X.copy()\n",
    "val_X_noMis  = val_X.copy()\n",
    "train_X_noMis = train_X_noMis.drop(cols_with_missing, axis=1)\n",
    "val_X_noMis  = val_X_noMis.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure what the 'quantile' loss function in GBR!\n",
    "\n",
    "#GradientBoostingRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def gbrPred(train_X, val_X, train_y,val_y,qt):\n",
    "    model = GradientBoostingRegressor(loss='quantile', alpha=qt)\n",
    "    model.fit(train_X,train_y)\n",
    "    \n",
    "    preds = model.predict(val_X)\n",
    "    return preds\n",
    "\n",
    "gbr05 = gbrPred(train_X_noMis, val_X_noMis, train_y,val_y,0.05)\n",
    "gbr50 = gbrPred(train_X_noMis, val_X_noMis, train_y,val_y,0.5)\n",
    "gbr95 = gbrPred(train_X_noMis, val_X_noMis, train_y,val_y,0.95)\n",
    "\n",
    "gbr_score = WPLoss(gbr05, gbr50, gbr95, val_y, val_X.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile linear regression\n",
    "#from mlinsights.mlmodel import QuantileLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep nets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
